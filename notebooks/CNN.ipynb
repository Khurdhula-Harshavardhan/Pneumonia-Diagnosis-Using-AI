{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook attempts to fit a Convolutional Neural Network over chest X-ray images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Define Constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "EPOCHS = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../datasets/train'\n",
    "test_dir = '../datasets/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Perform Data augmentation for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Preprocess the test data in simple manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Get training images in batches using train_data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4173 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training'  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Get validation images in batches using validation generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1043 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Define the CNN Architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Compile the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Create an early_stopping Callback to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "130/130 [==============================] - 163s 1s/step - loss: 0.5210 - accuracy: 0.7667 - val_loss: 0.3754 - val_accuracy: 0.8105\n",
      "Epoch 2/25\n",
      "130/130 [==============================] - 146s 1s/step - loss: 0.3607 - accuracy: 0.8298 - val_loss: 0.3339 - val_accuracy: 0.8330\n",
      "Epoch 3/25\n",
      "130/130 [==============================] - 140s 1s/step - loss: 0.2921 - accuracy: 0.8691 - val_loss: 0.3442 - val_accuracy: 0.8506\n",
      "Epoch 4/25\n",
      "130/130 [==============================] - 145s 1s/step - loss: 0.2831 - accuracy: 0.8785 - val_loss: 0.2760 - val_accuracy: 0.8730\n",
      "Epoch 5/25\n",
      "130/130 [==============================] - 138s 1s/step - loss: 0.2566 - accuracy: 0.8923 - val_loss: 0.2664 - val_accuracy: 0.8838\n",
      "Epoch 6/25\n",
      "130/130 [==============================] - 143s 1s/step - loss: 0.2386 - accuracy: 0.8983 - val_loss: 0.2867 - val_accuracy: 0.8701\n",
      "Epoch 7/25\n",
      "130/130 [==============================] - 136s 1s/step - loss: 0.2303 - accuracy: 0.9046 - val_loss: 0.2937 - val_accuracy: 0.8633\n",
      "Epoch 8/25\n",
      "130/130 [==============================] - 134s 1s/step - loss: 0.2317 - accuracy: 0.9085 - val_loss: 0.2896 - val_accuracy: 0.8652\n",
      "Epoch 9/25\n",
      "130/130 [==============================] - 134s 1s/step - loss: 0.2098 - accuracy: 0.9143 - val_loss: 0.2288 - val_accuracy: 0.8916\n",
      "Epoch 10/25\n",
      "130/130 [==============================] - 133s 1s/step - loss: 0.2029 - accuracy: 0.9203 - val_loss: 0.2047 - val_accuracy: 0.9141\n",
      "Epoch 11/25\n",
      "130/130 [==============================] - 138s 1s/step - loss: 0.1980 - accuracy: 0.9184 - val_loss: 0.2140 - val_accuracy: 0.9053\n",
      "Epoch 12/25\n",
      "130/130 [==============================] - 135s 1s/step - loss: 0.1831 - accuracy: 0.9256 - val_loss: 0.2532 - val_accuracy: 0.8887\n",
      "Epoch 13/25\n",
      "130/130 [==============================] - 136s 1s/step - loss: 0.1823 - accuracy: 0.9271 - val_loss: 0.1978 - val_accuracy: 0.9189\n",
      "Epoch 14/25\n",
      "130/130 [==============================] - 152s 1s/step - loss: 0.1798 - accuracy: 0.9290 - val_loss: 0.1925 - val_accuracy: 0.9180\n",
      "Epoch 15/25\n",
      "130/130 [==============================] - 158s 1s/step - loss: 0.1841 - accuracy: 0.9254 - val_loss: 0.2429 - val_accuracy: 0.8975\n",
      "Epoch 16/25\n",
      "130/130 [==============================] - 143s 1s/step - loss: 0.1694 - accuracy: 0.9324 - val_loss: 0.1925 - val_accuracy: 0.9092\n",
      "Epoch 17/25\n",
      "130/130 [==============================] - 145s 1s/step - loss: 0.1663 - accuracy: 0.9321 - val_loss: 0.1820 - val_accuracy: 0.9229\n",
      "Epoch 18/25\n",
      "130/130 [==============================] - 143s 1s/step - loss: 0.1667 - accuracy: 0.9326 - val_loss: 0.1965 - val_accuracy: 0.9199\n",
      "Epoch 19/25\n",
      "130/130 [==============================] - 150s 1s/step - loss: 0.1634 - accuracy: 0.9372 - val_loss: 0.1935 - val_accuracy: 0.9199\n",
      "Epoch 20/25\n",
      "130/130 [==============================] - 141s 1s/step - loss: 0.1612 - accuracy: 0.9384 - val_loss: 0.1624 - val_accuracy: 0.9248\n",
      "Epoch 21/25\n",
      "130/130 [==============================] - 141s 1s/step - loss: 0.1492 - accuracy: 0.9413 - val_loss: 0.1709 - val_accuracy: 0.9336\n",
      "Epoch 22/25\n",
      "130/130 [==============================] - 149s 1s/step - loss: 0.1574 - accuracy: 0.9362 - val_loss: 0.1638 - val_accuracy: 0.9375\n",
      "Epoch 23/25\n",
      "130/130 [==============================] - 147s 1s/step - loss: 0.1501 - accuracy: 0.9435 - val_loss: 0.1954 - val_accuracy: 0.9209\n",
      "Epoch 24/25\n",
      "130/130 [==============================] - 152s 1s/step - loss: 0.1415 - accuracy: 0.9406 - val_loss: 0.1593 - val_accuracy: 0.9346\n",
      "Epoch 25/25\n",
      "130/130 [==============================] - 145s 1s/step - loss: 0.1524 - accuracy: 0.9411 - val_loss: 0.1588 - val_accuracy: 0.9346\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
