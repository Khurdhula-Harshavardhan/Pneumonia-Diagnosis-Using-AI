{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook attempts to train a DenseNet121 pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from joblib import dump\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "EPOCHS = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../datasets/train'\n",
    "test_dir = '../datasets/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Perform Data Augmentation for the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Preprocess the test data in simple manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Get training images in batches using train_data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4173 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training'  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Get validation images in batches using validation generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1043 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    One way to fight imbalance is to have class weights defined and add penalty for misclassfying minority class.\n",
    "    - Generate samples, find weights and then use that to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "temp_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',  \n",
    "    shuffle=False  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Compute the class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(temp_generator.classes),\n",
    "    y=temp_generator.classes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Convert weights into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_dict = {i : class_weights[i] for i in range(len(class_weights))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Load the DenseNet121 model, pretrained on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DenseNet121 base model, pretrained on ImageNet\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The model performs terribly bad, due to overfitting.\n",
    "        - We must prevent it from overfitting. By using early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor the validation loss\n",
    "    patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,           # To print messages when the callback takes an action\n",
    "    restore_best_weights=True  # Optional: Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Add new layers on top of DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Now train this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Compile this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Train this modified ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "131/131 [==============================] - 201s 2s/step - loss: 0.2872 - accuracy: 0.8730 - val_loss: 0.6381 - val_accuracy: 0.7593\n",
      "Epoch 2/40\n",
      "131/131 [==============================] - 187s 1s/step - loss: 0.1947 - accuracy: 0.9243 - val_loss: 0.1991 - val_accuracy: 0.9214\n",
      "Epoch 3/40\n",
      "131/131 [==============================] - 183s 1s/step - loss: 0.1673 - accuracy: 0.9300 - val_loss: 0.1825 - val_accuracy: 0.9223\n",
      "Epoch 4/40\n",
      "131/131 [==============================] - 183s 1s/step - loss: 0.1955 - accuracy: 0.9195 - val_loss: 0.1600 - val_accuracy: 0.9367\n",
      "Epoch 5/40\n",
      "131/131 [==============================] - 183s 1s/step - loss: 0.1744 - accuracy: 0.9276 - val_loss: 0.1553 - val_accuracy: 0.9415\n",
      "Epoch 6/40\n",
      "131/131 [==============================] - 186s 1s/step - loss: 0.1439 - accuracy: 0.9401 - val_loss: 0.3708 - val_accuracy: 0.8639\n",
      "Epoch 7/40\n",
      "131/131 [==============================] - 188s 1s/step - loss: 0.1567 - accuracy: 0.9324 - val_loss: 0.2537 - val_accuracy: 0.8878\n",
      "Epoch 8/40\n",
      "131/131 [==============================] - 187s 1s/step - loss: 0.1581 - accuracy: 0.9329 - val_loss: 0.4168 - val_accuracy: 0.8198\n",
      "Epoch 9/40\n",
      "131/131 [==============================] - 189s 1s/step - loss: 0.1444 - accuracy: 0.9367 - val_loss: 0.1490 - val_accuracy: 0.9386\n",
      "Epoch 10/40\n",
      "131/131 [==============================] - 190s 1s/step - loss: 0.1373 - accuracy: 0.9410 - val_loss: 0.1575 - val_accuracy: 0.9396\n",
      "Epoch 11/40\n",
      "131/131 [==============================] - 190s 1s/step - loss: 0.1459 - accuracy: 0.9415 - val_loss: 0.1987 - val_accuracy: 0.9137\n",
      "Epoch 12/40\n",
      "131/131 [==============================] - 190s 1s/step - loss: 0.1323 - accuracy: 0.9434 - val_loss: 0.1220 - val_accuracy: 0.9473\n",
      "Epoch 13/40\n",
      "131/131 [==============================] - 190s 1s/step - loss: 0.1354 - accuracy: 0.9437 - val_loss: 0.2085 - val_accuracy: 0.9108\n",
      "Epoch 14/40\n",
      "131/131 [==============================] - 191s 1s/step - loss: 0.1389 - accuracy: 0.9446 - val_loss: 0.1545 - val_accuracy: 0.9329\n",
      "Epoch 15/40\n",
      "131/131 [==============================] - 191s 1s/step - loss: 0.1273 - accuracy: 0.9468 - val_loss: 0.1100 - val_accuracy: 0.9569\n",
      "Epoch 16/40\n",
      "131/131 [==============================] - 191s 1s/step - loss: 0.1204 - accuracy: 0.9518 - val_loss: 0.1216 - val_accuracy: 0.9511\n",
      "Epoch 17/40\n",
      "131/131 [==============================] - 192s 1s/step - loss: 0.1351 - accuracy: 0.9439 - val_loss: 0.2542 - val_accuracy: 0.9060\n",
      "Epoch 18/40\n",
      "131/131 [==============================] - 192s 1s/step - loss: 0.1228 - accuracy: 0.9449 - val_loss: 0.1147 - val_accuracy: 0.9559\n",
      "Epoch 19/40\n",
      "131/131 [==============================] - 192s 1s/step - loss: 0.1262 - accuracy: 0.9516 - val_loss: 0.1657 - val_accuracy: 0.9338\n",
      "Epoch 20/40\n",
      "131/131 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.9451Restoring model weights from the end of the best epoch: 15.\n",
      "131/131 [==============================] - 192s 1s/step - loss: 0.1265 - accuracy: 0.9451 - val_loss: 0.1792 - val_accuracy: 0.9262\n",
      "Epoch 20: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, \n",
    "                    epochs=EPOCHS, \n",
    "                    validation_data=validation_generator, \n",
    "                    class_weight=class_weight_dict,\n",
    "                    callbacks=[early_stopping])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
