{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook attempts to Fit a VGG16 pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from joblib import dump\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Let's set the primary hardware computational resource to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.device = tf.device(\"gpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "EPOCHS = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Data Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../datasets/train'\n",
    "test_dir = '../datasets/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Perform Data Augmentation for the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Preprocess the test data in simple manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4173 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training'  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Get validation images in batches using validation generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1043 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    One way to fight imbalance is to have class weights defined and add penalty for misclassfying minority class.\n",
    "    - Generate samples, find weights and then use that to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "temp_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',  \n",
    "    shuffle=False  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Compute the class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(temp_generator.classes),\n",
    "    y=temp_generator.classes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Convert weights into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_dict = {i : class_weights[i] for i in range(len(class_weights))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We must also incorporate early_stopping to prevent our layers from over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor the validation loss\n",
    "    patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,           # To print messages when the callback takes an action\n",
    "    restore_best_weights=True  # Optional: Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Load the VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Freeze the layers of the base model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Adding our custom layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Fit this modified VGG16:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "33/33 [==============================] - 368s 11s/step - loss: 1.1972 - accuracy: 0.7764 - val_loss: 0.3589 - val_accuracy: 0.8821\n",
      "Epoch 2/40\n",
      "33/33 [==============================] - 374s 11s/step - loss: 0.2686 - accuracy: 0.8967 - val_loss: 0.2619 - val_accuracy: 0.8763\n",
      "Epoch 3/40\n",
      "33/33 [==============================] - 375s 11s/step - loss: 0.1889 - accuracy: 0.9216 - val_loss: 0.2486 - val_accuracy: 0.9012\n",
      "Epoch 4/40\n",
      "33/33 [==============================] - 373s 11s/step - loss: 0.1845 - accuracy: 0.9255 - val_loss: 0.2400 - val_accuracy: 0.9012\n",
      "Epoch 5/40\n",
      "33/33 [==============================] - 375s 11s/step - loss: 0.1657 - accuracy: 0.9348 - val_loss: 0.1471 - val_accuracy: 0.9492\n",
      "Epoch 6/40\n",
      "33/33 [==============================] - 378s 11s/step - loss: 0.1596 - accuracy: 0.9329 - val_loss: 0.1481 - val_accuracy: 0.9386\n",
      "Epoch 7/40\n",
      "33/33 [==============================] - 388s 12s/step - loss: 0.1692 - accuracy: 0.9341 - val_loss: 0.2289 - val_accuracy: 0.9080\n",
      "Epoch 8/40\n",
      "33/33 [==============================] - 385s 12s/step - loss: 0.1662 - accuracy: 0.9269 - val_loss: 0.1201 - val_accuracy: 0.9626\n",
      "Epoch 9/40\n",
      "33/33 [==============================] - 379s 12s/step - loss: 0.1473 - accuracy: 0.9382 - val_loss: 0.2470 - val_accuracy: 0.9003\n",
      "Epoch 10/40\n",
      "33/33 [==============================] - 406s 12s/step - loss: 0.1466 - accuracy: 0.9403 - val_loss: 0.2723 - val_accuracy: 0.8811\n",
      "Epoch 11/40\n",
      "33/33 [==============================] - 389s 12s/step - loss: 0.1461 - accuracy: 0.9399 - val_loss: 0.1592 - val_accuracy: 0.9406\n",
      "Epoch 12/40\n",
      "33/33 [==============================] - 368s 11s/step - loss: 0.1409 - accuracy: 0.9384 - val_loss: 0.2536 - val_accuracy: 0.9051\n",
      "Epoch 13/40\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.1487 - accuracy: 0.9422Restoring model weights from the end of the best epoch: 8.\n",
      "33/33 [==============================] - 367s 11s/step - loss: 0.1487 - accuracy: 0.9422 - val_loss: 0.1792 - val_accuracy: 0.9233\n",
      "Epoch 13: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, \n",
    "                    epochs=EPOCHS, \n",
    "                    validation_data=validation_generator, \n",
    "                    class_weight=class_weight_dict,\n",
    "                    callbacks=[early_stopping])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
